{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qR4zKnZufxfi",
   "metadata": {
    "id": "qR4zKnZufxfi"
   },
   "source": [
    "# Popcorn Inventory Recommendations\n",
    "\n",
    "This iPython Notebook is a tool for suggesting inventory levels for different popcorn products at each storefront. For more information about how it can be used, see the external documentation.\n",
    "\n",
    "Note: Any time you change a cell, you must run that cell for changes to take effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cCcpUZImg9ll",
   "metadata": {
    "id": "cCcpUZImg9ll"
   },
   "source": [
    "Listed below are the libraries used in this file. If it is ever run offline, these python libraries will need to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd5f2e",
   "metadata": {
    "id": "6abd5f2e"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from math import ceil # round up function\n",
    "import datetime # handle dates\n",
    "import json # handle json data\n",
    "import pandas as pd # create dataframes (tables) and series of data\n",
    "import numpy as np # handle numeric computation\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import scipy.stats as st # statistical calculations\n",
    "from scipy.stats import burr, norm # distribution functions\n",
    "from sklearn.linear_model import LinearRegression # linear regression functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GQWU1IOGhJfH",
   "metadata": {
    "id": "GQWU1IOGhJfH"
   },
   "source": [
    "This file supports loading data from Google Drive. If you would like to use Google Drive for storing data, upload it and run the cell below. If not, don't run the cell. You can delete it, or stop it from running by putting # characters at the beginning of each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0EPybxWpfNxH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18185,
     "status": "ok",
     "timestamp": 1649778890145,
     "user": {
      "displayName": "Eric Yager",
      "userId": "11138110661529068789"
     },
     "user_tz": 300
    },
    "id": "0EPybxWpfNxH",
    "outputId": "66f79ff4-e1f8-4212-b208-fa86646392d4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UXzmOc3bDHgs",
   "metadata": {
    "id": "UXzmOc3bDHgs"
   },
   "source": [
    "## File Paths\n",
    "\n",
    "This code block tells the program where to look for the data files. If you are using Google Drive, the data_folder variable should begin with \"drive/MyDrive/\", with any further subfolders listed after. For example:\n",
    "```\n",
    "# data folder path\n",
    "data_folder = \"drive/MyDrive/data/\"\n",
    "```\n",
    "If you would rather simply upload the data files into Google Colab, you can put them in a folder:\n",
    "```\n",
    "# data folder path\n",
    "data_folder = \"data/\"\n",
    "```\n",
    "Or, if you just put them in the default files directory, use the following:\n",
    "```\n",
    "# data folder path\n",
    "data_folder = \"./\"\n",
    "```\n",
    "The period indicates we are using the current folder.\n",
    "\n",
    "For the files, make sure they are all in the same folder, which matches the folder path you gave above. Then, input the names of the files you would like to use into the variables below. For example:\n",
    "```\n",
    "# file path for sales history\n",
    "sales_history_filename = data_folder + \"PopcornSalesHistory.csv\"\n",
    "# file path for cost basis data\n",
    "cost_basis_filename = data_folder + \"flavor_pricing.csv\"\n",
    "# file path for product weights and best by periods\n",
    "shelf_life_filename = data_folder + \"shelf_lives.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c9433",
   "metadata": {
    "id": "731c9433"
   },
   "outputs": [],
   "source": [
    "# FILE PATHS\n",
    "# data folder path\n",
    "data_folder = \"drive/MyDrive/data/\"\n",
    "# file path for sales history\n",
    "sales_history_filename = data_folder + \"PopcornSalesHistory.csv\"\n",
    "# file path for cost basis data\n",
    "cost_basis_filename = data_folder + \"flavor_pricing.csv\"\n",
    "# file path for product weights and best by periods\n",
    "shelf_life_filename = data_folder + \"shelf_lives.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "snaBO1_4D6-G",
   "metadata": {
    "id": "snaBO1_4D6-G"
   },
   "source": [
    "## Configurable Variables\n",
    "These variables can be changed to modify how the code works and what type of data it will output. \n",
    "* `target_products`: This is a list of the flavors to get inventory recommendations for. If you choose to edit it, be sure each flavor is in quotation marks, different flavors are separated by a comma, and that there are square brackets at the beginning and end of the list.\n",
    "* `target_locations`: This is a list of the locations to make suggestions for. The same editing rules apply as when editing `target_products`.\n",
    "* `sizes`: These are the size names to consider when making suggestions. The same editing rules apply as when editing `target_products` and `target_locations`, as this is another list.\n",
    "* `start_date_string`: The data prior to a particular date may be too outdated to use. Change this variable to change when sales history data first starts to be considered. It must be a date in the format \"YYYY-MM-DD\".\n",
    "* `forecast_week`: This variable changes how many weeks in advance we are forecasting. The default (zero) is to suggest inventory for the week beginning the next Sunday (or today, if today is Sunday). Increasing this number forecasts that number of weeks past the default week. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1d354",
   "metadata": {
    "id": "d2c1d354"
   },
   "outputs": [],
   "source": [
    "# CONFIGURABLE VARIABLES\n",
    "# some are redacted to avoid violating our NDA\n",
    "target_products = [\"redacted\"]\n",
    "# limited the locations I'm considering, also for lack of data\n",
    "target_locations = [\"redacted\"]\n",
    "# limited sizes, same reason\n",
    "sizes = [\"redacted\"]\n",
    "# option to remove large orders\n",
    "remove_large_orders = False\n",
    "# forecast week\n",
    "# 0 will forecast the next week, 1 will forecast the week after, etc.\n",
    "forecast_week = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mR-ZzidtmGYi",
   "metadata": {
    "id": "mR-ZzidtmGYi"
   },
   "source": [
    "## Functions\n",
    "The functions below are essential to the operation of the suggestion program. They should only be modified by someone who definitely knows what they're doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e1b23",
   "metadata": {
    "id": "e62e1b23"
   },
   "outputs": [],
   "source": [
    "def within_days_before(date, days, day, month, year=None):\n",
    "    \"\"\"This function indicates whether a date is within a certain number of \n",
    "    days prior to another date. \n",
    "\n",
    "    Parameters:\n",
    "    date (datetime.date): the date we are checking to see if it is close to \n",
    "        another date\n",
    "    days (int): the number of days within which date is of the other day\n",
    "    day (int): day of the month for the target date\n",
    "    month (int): month 1-12 of the target date\n",
    "    year (int): if there is a particular year, this is it. If None, checks all\n",
    "        surrounding years\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the date is within `days` days of the specified date, False\n",
    "        otherwise\n",
    "    \"\"\"\n",
    "    if year==None:\n",
    "        targets = [\n",
    "            # the current year\n",
    "            datetime.date(year=date.year, month=month, day=day),\n",
    "            # the next year, in case the target date already happened this year\n",
    "            datetime.date(year=date.year+1, month=month, day=day)\n",
    "        ]\n",
    "    else:\n",
    "        # if a year is given, use that year\n",
    "        targets = [datetime.date(year=year, month=month, day=day)]\n",
    "    # if the date is within the given day in any of the possible target years, \n",
    "    # return true\n",
    "    return np.any([0 < (t-date).days <= days for t in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a3df6",
   "metadata": {
    "id": "a22a3df6"
   },
   "outputs": [],
   "source": [
    "def my_cdf(x, c, d, loc, scale, date, b0, b1, min_residual):\n",
    "    \"\"\"This function calculates the value of the burr cumulative distribution\n",
    "    of the residual for x for a given linear regression.\n",
    "\n",
    "    Parameters:\n",
    "    x (float): the sales values for a given date\n",
    "    c (float): the constant c for the burr distribution\n",
    "    d (float): the constant d for the burr distribution\n",
    "    loc (float): the x location of the burr distribution\n",
    "    scale (float): the scaling factor of the burr distribution\n",
    "    date (int): the date in ordinal form (use datetime.date.toordinal())\n",
    "    b0 (float): the y-intercept of the regression\n",
    "    b1 (float): the slope of the regression\n",
    "    min_residual (float): the minimum residual, added to the residual to insure \n",
    "    it is not zero\n",
    "\n",
    "    Returns:\n",
    "    float: the value of the CDF at the given location\n",
    "    \"\"\"\n",
    "    # first, find the residual based on the regression\n",
    "    residual = max([x-(date*b1 + b0)-min_residual,0])\n",
    "    # next, find the cdf of the residual\n",
    "    return burr.cdf(residual, c, d, loc=loc, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfbb66",
   "metadata": {
    "id": "3ecfbb66"
   },
   "outputs": [],
   "source": [
    "def get_weekly_sales(sales_df):\n",
    "    \"\"\"Create the weekly sales data from a give dataframe of sales.\n",
    "\n",
    "    Parameters:\n",
    "    sales_df (pandas.DataFrame): a dataframe of sales data; if you only want \n",
    "        to examine one flavor, remove all the others BEFORE passing it here\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: a dataframe containing columns for the week and for the \n",
    "        sales quantity during that week\n",
    "    \"\"\"\n",
    "    # sum the total quantity sold for each day to get daily sales\n",
    "    daily_sales = sales_df[[\"Date\", \"Total quantity sold\"]].groupby(\"Date\").apply(np.sum)[[\"Total quantity sold\"]]\n",
    "    # convert the date to a datetime.date object for each daily sales row\n",
    "    daily_sales[\"datetime\"] = [datetime.date(int(row[0][:4]),int(row[0][5:7]),int(row[0][8:])) for row in daily_sales.iterrows()]\n",
    "    # i want the week to start with sunday, so find the sunday immediately preceding the start of the data set\n",
    "    first_day = min(daily_sales[\"datetime\"])-datetime.timedelta(days=1+min(daily_sales[\"datetime\"]).weekday())\n",
    "    # create a dictionary to hold lists of the week and sales\n",
    "    weekly_sales = {'week':[], 'sales':[]}\n",
    "    # loop over every sunday over the whole data set\n",
    "    for i in range(ceil((max(daily_sales[\"datetime\"])-first_day).days/7)):\n",
    "        # add the week to the weeks list\n",
    "        weekly_sales['week'].append(first_day + datetime.timedelta(days=i*7))\n",
    "        # add the sum of the sales for every day in the next 7 days to the sales list\n",
    "        weekly_sales['sales'].append(np.sum(daily_sales[[first_day+datetime.timedelta(days=7*i) <= x <= first_day+datetime.timedelta(days=7*(i+1)) for x in daily_sales[\"datetime\"]]][\"Total quantity sold\"]))\n",
    "    # remove the last week because it is incomplete\n",
    "    weekly_sales = pd.DataFrame(weekly_sales, index=weekly_sales['week']).iloc[:-1,:].copy()\n",
    "    return weekly_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022752a",
   "metadata": {
    "id": "3022752a"
   },
   "outputs": [],
   "source": [
    "def open_data_files():\n",
    "    \"\"\"This is a helper function for opening all the files, it uses the \n",
    "    file paths given at the beginning.\n",
    "\n",
    "    Returns\n",
    "    pd.DataFrame: Dataframe of sales data\n",
    "    pd.DataFrame: Dataframe of cost basis data\n",
    "    pd.DataFrame: Dataframe of shelf life data\n",
    "    \"\"\"\n",
    "    # open sales data\n",
    "    sales = pd.read_csv(sales_history_filename)\n",
    "    # substitute location IDs with strings\n",
    "    sales['Order Location Id'] = [KNOWN_LOCATIONS[int(x)] for x in sales['Order Location Id']]\n",
    "    # open cost basis data\n",
    "    cost_basis_data = pd.read_csv(cost_basis_filename, index_col=0)\n",
    "    # open shelf life data\n",
    "    shelf_lives = pd.read_csv(shelf_life_filename)\n",
    "    return (sales, cost_basis_data, shelf_lives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06035d1e",
   "metadata": {
    "id": "06035d1e"
   },
   "outputs": [],
   "source": [
    "def get_needed_forecast(weekly_sales):\n",
    "    \"\"\"Get the flavor category for a given flavor.\n",
    "\n",
    "    Parameters:\n",
    "    weekly_sales (pandas.DataFrame): a dataframe containing weekly sales for the data\n",
    "\n",
    "    Returns:\n",
    "    int: the number of weeks between the end of the dataset and next week\n",
    "    \"\"\"\n",
    "    last_date = max(weekly_sales.week)\n",
    "    today = datetime.date.today()\n",
    "    next_week = today+datetime.timedelta(days=6-today.weekday())\n",
    "    return int((next_week-last_date).days/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R6snq4iEIbEm",
   "metadata": {
    "id": "R6snq4iEIbEm"
   },
   "source": [
    "### Inventory Suggestions Function\n",
    "The function below is the primary function for making the inventory suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1dd28d",
   "metadata": {
    "id": "fb1dd28d"
   },
   "outputs": [],
   "source": [
    "def get_inventory_suggestions(weekly_sales, profit_per_unit, cost_basis, shelf_life_weeks, forecast_length=52):\n",
    "    \"\"\"Adds a column to the weekly_sales dataframe with suggested inventory \n",
    "    levels.\n",
    "\n",
    "    This algorithm consists of two main parts:\n",
    "    1. Construct a probability distribution of expected sales for a given week. \n",
    "    2. Use the probability distribution to maximize inventory while keeping \n",
    "       expected sales:waste ratio within a given constraint.\n",
    "\n",
    "    Presently, the probability distribution is constructed by fitting a Burr\n",
    "    distribution to the residuals of a simple linear regression on weekly\n",
    "    sales. This could be swapped for another method for constructing a \n",
    "    probability distribution.\n",
    "\n",
    "    The second part of the algorithm could also potentially be replaced, but \n",
    "    the goal should still be to have enough in inventory to meet demand most\n",
    "    weeks, but not to waste very much over the course of a shelf-life period.\n",
    "\n",
    "    Parameters:\n",
    "    weekly_sales (pandas.DataFrame): a dataframe containing weekly sales for the data\n",
    "    profit_per_unit (float): the profit per unit sold (price minus cost basis)\n",
    "    cost_basis (float): the cost to produce a given product\n",
    "    shelf_life_weeks (float): the shelf life of the product in weeks\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Dataframe containing weekly sales and recommended \n",
    "    inventory levels\n",
    "    \"\"\"\n",
    "    ### remove 4 weeks preceding christmas (huge outliers)\n",
    "    # copy the sales data frame \n",
    "    weekly_sales_no_christmas = weekly_sales.copy()\n",
    "    # for each year in the data set\n",
    "    for year in set([d.year for d in weekly_sales_no_christmas['week']]):\n",
    "        # set the sales value for the 4 weeks preceding Christmas to the \n",
    "        # average sales in that year prior to the 4 weeks preceding Christmas\n",
    "        weekly_sales_no_christmas.loc[weekly_sales['week'].apply(within_days_before, args=(28, 25, 12),year=year),'sales'] = np.average(weekly_sales[(~weekly_sales['week'].apply(within_days_before, args=(28, 25, 12)))&([d.month!=12 for d in weekly_sales['week']])&([d.year==year for d in weekly_sales['week']])]['sales'])\n",
    "    \n",
    "    ### linear regression on sales without christmas, calculate residuals\n",
    "    # fit a linear regression with date as explanatory variable and sales as dependent variable\n",
    "    reg = LinearRegression().fit(np.array([d.toordinal() for d in weekly_sales_no_christmas.week]).reshape(-1,1), np.array(list(weekly_sales_no_christmas.sales)).reshape(-1,1))\n",
    "    # get the regression predicted values for each week\n",
    "    y_pred = reg.predict(np.array([d.toordinal() for d in weekly_sales_no_christmas.week]).reshape(-1,1))\n",
    "    # get the regression parameters (y interept and slope)\n",
    "    reg_params = [reg.intercept_[0], reg.coef_[0][0]]\n",
    "    #if reg_params[1]<0:\n",
    "    #    reg_params[1]=0\n",
    "    #    reg_params[0]=(y_pred[-1]+y_pred[0])/2\n",
    "    # add the regression predictions to the dataframe\n",
    "    weekly_sales_no_christmas['reg_pred'] = y_pred.reshape(-1)\n",
    "    # create residuals from the regression by subtracting the regression \n",
    "    # predictions from the true values\n",
    "    weekly_sales_no_christmas['residuals'] = weekly_sales_no_christmas['sales']-weekly_sales_no_christmas['reg_pred']\n",
    "    # because the burr distribution only works for positive values, normalize \n",
    "    # all the residuals to be greater than or equal to zero\n",
    "    weekly_sales_no_christmas['pos_residuals'] = [x-min(weekly_sales_no_christmas['residuals']) for x in weekly_sales_no_christmas['residuals']]\n",
    "    \n",
    "    ### fit burr distribution to regression residuals\n",
    "    # a dictionary for storing the parmeters needed to specify a burr \n",
    "    # distribution\n",
    "    burr_params = {}\n",
    "    # fit the burr distribution to the positive residuals and unpack the \n",
    "    # parameters into the dictionary\n",
    "    burr_params['c'], burr_params['d'], burr_params['loc'], burr_params['scale'] = burr.fit(weekly_sales_no_christmas['pos_residuals'])\n",
    "    \n",
    "    ### set inventory levels\n",
    "    # get the first day from the sales data\n",
    "    first_date = min(weekly_sales.week)\n",
    "    # create a dictionary to store both the week and the suggested inventory\n",
    "    inventory_levels = {'week':[],'inventory':[]}\n",
    "    # for each week plus some number of forecasting\n",
    "    for i in range(len(weekly_sales)+forecast_length):\n",
    "        # initialize profit to absurdly high\n",
    "        profit_loss = 9999999\n",
    "        # initialize inventory to zero\n",
    "        inventory = 0\n",
    "        # set the week to the starting week plus the current index\n",
    "        # this allows us to loop over every week\n",
    "        week = first_date+datetime.timedelta(days=7*i)\n",
    "        # create the list of params to use for the my_cdf() function\n",
    "        params = list(burr_params.values())+[week.toordinal(), reg_params[0], reg_params[1], min(weekly_sales_no_christmas['residuals'])]\n",
    "        # while the profit/loss ratio is better than the minimum desired ratio\n",
    "        while profit_loss > pl_ratio:\n",
    "            # increment the amount in inventory\n",
    "            inventory+=1\n",
    "            # expected profit is the probability we will sell more than the \n",
    "            # current inventory times profit per unit\n",
    "            expected_profit = (1-my_cdf(inventory,*params))*profit_per_unit\n",
    "            # expected loss is the probability we will sell less than the \n",
    "            # current inventory, divided by shelf life in weeks, times the \n",
    "            # cost basis per unit\n",
    "            expected_loss = (my_cdf(inventory-1, *params)**(shelf_life_weeks))*cost_basis\n",
    "            # profit loss ratio, but make sure we don't divide by zero\n",
    "            profit_loss = expected_profit/max([expected_loss,0.0001])\n",
    "        # when the loop is completed, we've found the maximum viable inventory\n",
    "        # level, so we add the week to the weeks list\n",
    "        inventory_levels['week'].append(week)\n",
    "        # and we add the inventory level to the inventory list\n",
    "        inventory_levels['inventory'].append(inventory)\n",
    "    # once we've found the inventory for every week, we create a series from \n",
    "    # the dictionary because it is more convenient to add this to the dataframe\n",
    "    inventory_levels = pd.Series(inventory_levels['inventory'], index=inventory_levels['week'], name=\"inventory_suggest\")\n",
    "    # then, we add the inventory suggestions to the dataframe without christmas\n",
    "    weekly_sales_no_christmas = pd.concat([weekly_sales_no_christmas, inventory_levels], axis=1)\n",
    "    \n",
    "    ### account for the 4 weeks preceding Christmas\n",
    "    # get the 4 weeks preceding christmas for each year in the data set\n",
    "    christmas_weeks = weekly_sales.loc[weekly_sales['week'].apply(within_days_before, args=(28, 25, 12)),'week']\n",
    "    # calculate the residuals for these weeks compared to the regresssion \n",
    "    christmas_residuals = np.array([weekly_sales.loc[w,\"sales\"] - reg.predict(np.array([w.toordinal()]).reshape(-1,1))[0] for w in christmas_weeks]).reshape((-1, 4))\n",
    "    # the average residual uses a weighted average, where every additional year \n",
    "    # between the given year and the present halves the given year's influence\n",
    "    # in the weighted average\n",
    "    average_residual = [sum([val*(i+1)/(2**(len(column))-1) for i, val in enumerate(column)]) for column in christmas_residuals.T]\n",
    "    # add the inventory suggestions to the dataframe with christmas\n",
    "    weekly_sales = pd.concat((weekly_sales, weekly_sales_no_christmas['inventory_suggest']),axis=1)\n",
    "    # update the week attribute to include the additional weeks we just added\n",
    "    weekly_sales['week'] =pd.Series(weekly_sales.index.values, index=weekly_sales.index)\n",
    "    # update the christmas weeks to include any weeks we are forecasting for\n",
    "    # the future\n",
    "    christmas_weeks = weekly_sales.loc[weekly_sales['week'].apply(within_days_before, args=(28, 25, 12)),'week']\n",
    "    # for each week in the christmas weeks\n",
    "    for i, w in enumerate(christmas_weeks):\n",
    "        # add the calculated weighted average (or zero, if it is somehow negative)\n",
    "        weekly_sales.loc[w, 'inventory_suggest'] += (ceil(average_residual[i%4]) if average_residual[i%4]>0 else 0)\n",
    "    \n",
    "    ### return the dataframe that now contains inventory suggestions\n",
    "    return weekly_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J7igUeJPOISV",
   "metadata": {
    "id": "J7igUeJPOISV"
   },
   "source": [
    "## Main Program Functionality\n",
    "The cell below contains the main functionality of the program. Running this cell (as long as all other needed cells have already been run) will generate inventory recommendations for the selected products and locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf484c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83796,
     "status": "ok",
     "timestamp": 1649778996049,
     "user": {
      "displayName": "Eric Yager",
      "userId": "11138110661529068789"
     },
     "user_tz": 300
    },
    "id": "7cf484c2",
    "outputId": "e7b06266-abc9-4a4b-af7e-472eebf5fe24"
   },
   "outputs": [],
   "source": [
    "# allow pandas to print more rows of dataframes\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# open all data\n",
    "sales, cost_basis_data, shelf_lives = open_data_files()\n",
    "# the probailities to use for the conservative, neutral, and aggressive\n",
    "probabilities = [0.4, 1, 2.5]\n",
    "# for each location\n",
    "for location in target_locations:\n",
    "    all_products = []\n",
    "    conservative = []\n",
    "    neutral = []\n",
    "    aggressive = []\n",
    "    # and for each product\n",
    "    for product in target_products:\n",
    "        # and for each size\n",
    "        for size in sizes:\n",
    "            all_products.append((product + ' ' + size).replace(\" \", \"_\"))\n",
    "            for pl_ratio in probabilities:\n",
    "                # get the sales only for that product and size and location\n",
    "                flavor_sales = sales[(\n",
    "                    (sales[\"Product name\"]==product) & \n",
    "                    (sales[\"Order Location Id\"]==location) &\n",
    "                    (sales[\"Variant name\"]==size) &\n",
    "                    (sales[\"Date\"]>start_date_string)\n",
    "                )].copy()\n",
    "                # if we are removing large orders, remove them\n",
    "                if remove_large_orders:\n",
    "                    # currently, this removes orders 3 standard deviations above\n",
    "                    # the mean, but we may want to use a method that relies less\n",
    "                    # on normality\n",
    "                    flavor_sales = flavor_sales[sales[\"Total sales\"]<=np.average(sales[\"Total sales\"])+3*np.std(sales[\"Total sales\"])].copy()\n",
    "                # if there are fewer than 10 sales, we just skip this data\n",
    "                if len(flavor_sales)<10:\n",
    "                    if pl_ratio < 1:\n",
    "                        aggressive.append(0)\n",
    "                    elif pl_ratio > 1:\n",
    "                        conservative.append(0)\n",
    "                    else:\n",
    "                        neutral.append(0)\n",
    "                    continue\n",
    "                ### get variables about product\n",
    "                # get the dataframe of weekly sales\n",
    "                weekly_sales = get_weekly_sales(flavor_sales)\n",
    "                # get the sales price of the current flavor\n",
    "                price = flavor_sales['Variant Price'].iloc[0]\n",
    "                # get the cost basis of the current flavor\n",
    "                cost_basis = cost_basis_data.loc[product, size]\n",
    "                # get the profit margin by substracting price from the cost basis\n",
    "                profit_margin = price - cost_basis\n",
    "                # get the product shelf life\n",
    "                shelf_life_weeks = shelf_lives.loc[shelf_lives['product'] == product, 'shelf_life_weeks'].iloc[0]\n",
    "                # get inventory suggestions\n",
    "                weekly_sales = get_inventory_suggestions(weekly_sales, profit_margin, cost_basis, shelf_life_weeks, forecast_length=get_needed_forecast(weekly_sales)+forecast_week)\n",
    "                if pl_ratio < 1:\n",
    "                    aggressive.append(weekly_sales.inventory_suggest[-1])\n",
    "                elif pl_ratio > 1:\n",
    "                    conservative.append(weekly_sales.inventory_suggest[-1])\n",
    "                else:\n",
    "                    neutral.append(weekly_sales.inventory_suggest[-1])\n",
    "    this_week_inventory = pd.DataFrame({\n",
    "        'conservative': conservative,\n",
    "        'neutral': neutral,\n",
    "        'aggressive': aggressive},\n",
    "        index=all_products)\n",
    "    print(location)\n",
    "    print(this_week_inventory[(this_week_inventory != 0).any(1)])\n",
    "# print(f\"average profit {sum(profits)/len(profits)} with ratio {pl_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ddc11",
   "metadata": {
    "id": "9c4ddc11"
   },
   "source": [
    "Conservative indicates a higher likelihood of stockout, but lower likelihood of having waste. Aggressive indicates a higher likelihood of waste, but lower likelihood of stocking out."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "inventory_recommender.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
